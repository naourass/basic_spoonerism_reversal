{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "*Import the list of correct english words and provide the corpus of the riddle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dict\n",
    "\n",
    "text = \"\"\"\n",
    "    \"IN THE NAME OF MAX FOSH, DISH OUT THE FISH\"\n",
    "    THAT'S ALL YOU NEED TO SPOUT\n",
    "    EXACTLY WHO TO ASK AND HOW?\n",
    "    JUST USE MY VID TO FIND OUT\n",
    "    TO CLAIM THE PRECIOUS TROUT\n",
    "    NEIGHBOUR ON THE BUS OR A DEAR OLD QUEEN\n",
    "    WITH THE POSSIBILITY THE WORLD IS PACKED\n",
    "    BUT THE KEEPER OF THE SECRET IS NOT CLOSE TO MAX\n",
    "    AND THAT'S BEYOND A FACT\n",
    "    DANCE IN A CRAZY WAY, USE A SQUEAKY VOICE\n",
    "    POST ON TIKTOK VIDEOS?\n",
    "    NO NEED TO SPAM OR GUESS OR STIR THINGS UP\n",
    "    JUST COPY WHAT THIS SILLY SONG SHOWS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "*Remove unwanted characters, split the text input into a list of lines, get another list with all words of the corpus*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IN THE NAME OF MAX FOSH, DISH OUT THE FISH',\n",
       " \"THAT'S ALL YOU NEED TO SPOUT\",\n",
       " 'EXACTLY WHO TO ASK AND HOW',\n",
       " 'JUST USE MY VID TO FIND OUT',\n",
       " 'TO CLAIM THE PRECIOUS TROUT',\n",
       " 'NEIGHBOUR ON THE BUS OR A DEAR OLD QUEEN',\n",
       " 'WITH THE POSSIBILITY THE WORLD IS PACKED',\n",
       " 'BUT THE KEEPER OF THE SECRET IS NOT CLOSE TO MAX',\n",
       " \"AND THAT'S BEYOND A FACT\",\n",
       " 'DANCE IN A CRAZY WAY, USE A SQUEAKY VOICE',\n",
       " 'POST ON TIKTOK VIDEOS',\n",
       " 'NO NEED TO SPAM OR GUESS OR STIR THINGS UP',\n",
       " 'JUST COPY WHAT THIS SILLY SONG SHOWS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted_chars = [\"?\", \"\\\"\"]\n",
    "sentence_divider = \"\\n    \"\n",
    "\n",
    "for c in unwanted_chars:\n",
    "    text = text.replace(c, \"\")\n",
    "\n",
    "lines = text.strip().split(sentence_divider)\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN', 'THE', 'NAME', 'OF', 'MAX', 'FOSH,', 'DISH', 'OUT', 'THE', 'FISH', \"THAT'S\", 'ALL', 'YOU', 'NEED', 'TO', 'SPOUT', 'EXACTLY', 'WHO', 'TO', 'ASK', 'AND', 'HOW', 'JUST', 'USE', 'MY', 'VID', 'TO', 'FIND', 'OUT', 'TO', 'CLAIM', 'THE', 'PRECIOUS', 'TROUT', 'NEIGHBOUR', 'ON', 'THE', 'BUS', 'OR', 'A', 'DEAR', 'OLD', 'QUEEN', 'WITH', 'THE', 'POSSIBILITY', 'THE', 'WORLD', 'IS', 'PACKED', 'BUT', 'THE', 'KEEPER', 'OF', 'THE', 'SECRET', 'IS', 'NOT', 'CLOSE', 'TO', 'MAX', 'AND', \"THAT'S\", 'BEYOND', 'A', 'FACT', 'DANCE', 'IN', 'A', 'CRAZY', 'WAY,', 'USE', 'A', 'SQUEAKY', 'VOICE', 'POST', 'ON', 'TIKTOK', 'VIDEOS', 'NO', 'NEED', 'TO', 'SPAM', 'OR', 'GUESS', 'OR', 'STIR', 'THINGS', 'UP', 'JUST', 'COPY', 'WHAT', 'THIS', 'SILLY', 'SONG', 'SHOWS']\n"
     ]
    }
   ],
   "source": [
    "words = [word for line in lines for word in line.split()]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan sentence by sentence\n",
    "*Generate possible spoonerism in each line of the corpus*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the'] => ['he', 'tin']\n",
      "['in', 'of'] => ['on', 'if']\n",
      "['the', 'out'] => ['tout', 'he']\n",
      "['max', 'fish'] => ['mash', 'fix']\n",
      "['need', 'to'] => ['teed', 'no']\n",
      "['who', 'and'] => ['wand', 'ho']\n",
      "['to', 'how'] => ['ho', 'tow']\n",
      "['just', 'out'] => ['oust', 'jut']\n",
      "['use', 'to'] => ['toe', 'us']\n",
      "['use', 'find'] => ['fin', 'used']\n",
      "['on', 'the'] => ['he', 'ton']\n",
      "['on', 'dear'] => ['or', 'dean']\n",
      "['on', 'dear'] => ['den', 'oar']\n",
      "['on', 'dear'] => ['ear', 'don']\n",
      "['the', 'bus'] => ['thus', 'be']\n",
      "['the', 'old'] => ['told', 'he']\n",
      "['bus', 'old'] => ['bold', 'us']\n",
      "['or', 'dear'] => ['ear', 'dor']\n",
      "['or', 'queen'] => ['on', 'queer']\n",
      "['dear', 'queen'] => ['dean', 'queer']\n",
      "['with', 'world'] => ['wild', 'worth']\n",
      "['with', 'packed'] => ['path', 'wicked']\n",
      "['but', 'is'] => ['bus', 'it']\n",
      "['but', 'not'] => ['no', 'butt']\n",
      "['of', 'not'] => ['no', 'oft']\n",
      "['not', 'close'] => ['clot', 'nose']\n",
      "['not', 'to'] => ['tot', 'no']\n",
      "['dance', 'a'] => ['ace', 'dan']\n",
      "['need', 'to'] => ['teed', 'no']\n",
      "['copy', 'shows'] => ['cops', 'showy']\n",
      "['this', 'song'] => ['thing', 'sos']\n",
      "['this', 'song'] => ['sis', 'thong']\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    res = []\n",
    "    line_words = line.split()\n",
    "    for word in line_words:\n",
    "        word = word.lower()\n",
    "        for other in line_words:\n",
    "            other = other.lower()\n",
    "            if word == other: continue\n",
    "            for i in range(1,4):\n",
    "                for j in range(1,4):\n",
    "                    affw = word[:i] # prefix of word a\n",
    "                    affo = other[:j] # prefix of word b\n",
    "                    suffw = word[-i:] # suffix of word a\n",
    "                    suffo = other[-j:] # suffix of word b\n",
    "\n",
    "                    spnw = affo + word[i:] # spooned a\n",
    "                    spno = affw + other[j:] # spooned b\n",
    "                    if spnw in dict and spno in dict:\n",
    "                        skip = (spnw == word or spno == other or spnw == spno or spnw == other or spno == word)\n",
    "                        skip = skip or (f\"{[word, other]} => {[spnw, spno]}\" in res or f\"{[other, word]} => {[spno, spnw]}\" in res)\n",
    "                        skip = skip or (f\"{[word, other]} => {[spno, spnw]}\" in res or f\"{[other, word]} => {[spnw, spno]}\" in res)\n",
    "                        if not skip:\n",
    "                            res.append(f\"{[word, other]} => {[spnw, spno]}\")\n",
    "\n",
    "                    spnw = word[:-i] + suffo\n",
    "                    spno = other[:-j] + suffw\n",
    "                    if spnw in dict and spno in dict:\n",
    "                        skip = (spnw == word or spno == other or spnw == spno or spnw == other or spno == word)\n",
    "                        skip = skip or (f\"{[word, other]} => {[spnw, spno]}\" in res or f\"{[other, word]} => {[spno, spnw]}\" in res)\n",
    "                        skip = skip or (f\"{[word, other]} => {[spno, spnw]}\" in res or f\"{[other, word]} => {[spnw, spno]}\" in res)\n",
    "                        if not skip:\n",
    "                            res.append(f\"{[word, other]} => {[spnw, spno]}\")\n",
    "\n",
    "    for i, el in enumerate(res):\n",
    "        print(el)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan all sentences at once\n",
    "*Generate possible spoonerism in the whole corpus at once*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the'] => ['he', 'tin']\n",
      "['in', 'of'] => ['on', 'if']\n",
      "['in', 'all'] => ['an', 'ill']\n",
      "['in', 'spout'] => ['out', 'spin']\n",
      "['in', 'who'] => ['ho', 'win']\n",
      "['in', 'ask'] => ['as', 'ink']\n",
      "['in', 'find'] => ['id', 'finn']\n",
      "['in', 'bus'] => ['is', 'bun']\n",
      "['in', 'bus'] => ['us', 'bin']\n",
      "['in', 'dear'] => ['ear', 'din']\n",
      "['in', 'but'] => ['it', 'bun']\n",
      "['in', 'not'] => ['it', 'non']\n",
      "['in', 'fact'] => ['act', 'fin']\n",
      "['in', 'spam'] => ['im', 'span']\n",
      "['in', 'spam'] => ['am', 'spin']\n",
      "['in', 'what'] => ['hat', 'win']\n",
      "['in', 'this'] => ['is', 'thin']\n",
      "['in', 'this'] => ['his', 'tin']\n",
      "['in', 'shows'] => ['is', 'shown']\n",
      "['the', 'out'] => ['tout', 'he']\n",
      "['the', 'all'] => ['tall', 'he']\n",
      "['the', 'you'] => ['thou', 'ye']\n",
      "['the', 'ask'] => ['task', 'he']\n",
      "['the', 'use'] => ['us', 'thee']\n",
      "['the', 'my'] => ['thy', 'me']\n",
      "['the', 'on'] => ['ton', 'he']\n",
      "['the', 'bus'] => ['thus', 'be']\n",
      "['the', 'old'] => ['told', 'he']\n",
      "['the', 'crazy'] => ['thy', 'craze']\n",
      "['the', 'spam'] => ['spa', 'them']\n",
      "['the', 'copy'] => ['thy', 'cope']\n",
      "['the', 'copy'] => ['cop', 'they']\n",
      "['name', 'to'] => ['tame', 'no']\n",
      "['name', 'to'] => ['nato', 'me']\n",
      "['name', 'dear'] => ['dame', 'near']\n",
      "['name', 'things'] => ['the', 'namings']\n",
      "['of', 'dear'] => ['or', 'deaf']\n",
      "['of', 'not'] => ['no', 'oft']\n",
      "['max', 'fish'] => ['mash', 'fix']\n",
      "['max', 'find'] => ['fax', 'mind']\n",
      "['max', 'on'] => ['man', 'ox']\n",
      "['max', 'or'] => ['mar', 'ox']\n",
      "['max', 'post'] => ['mast', 'pox']\n",
      "['dish', 'all'] => ['ash', 'dill']\n",
      "['out', 'just'] => ['jut', 'oust']\n",
      "['out', 'claim'] => ['aim', 'clout']\n",
      "['out', 'bus'] => ['us', 'bout']\n",
      "['out', 'post'] => ['oust', 'pot']\n",
      "['out', 'spam'] => ['am', 'spout']\n",
      "['out', 'this'] => ['his', 'tout']\n",
      "['fish', 'all'] => ['ash', 'fill']\n",
      "['fish', 'and'] => ['ash', 'find']\n",
      "['fish', 'dear'] => ['dish', 'fear']\n",
      "['fish', 'but'] => ['fit', 'bush']\n",
      "['fish', 'post'] => ['fist', 'posh']\n",
      "['all', 'who'] => ['ho', 'wall']\n",
      "['all', 'find'] => ['fill', 'and']\n",
      "['all', 'bus'] => ['bull', 'as']\n",
      "['all', 'bus'] => ['us', 'ball']\n",
      "['all', 'is'] => ['ill', 'as']\n",
      "['all', 'but'] => ['bull', 'at']\n",
      "['all', 'fact'] => ['fall', 'act']\n",
      "['all', 'copy'] => ['cop', 'ally']\n",
      "['all', 'what'] => ['hat', 'wall']\n",
      "['all', 'this'] => ['his', 'tall']\n",
      "['you', 'song'] => ['so', 'young']\n",
      "['need', 'to'] => ['teed', 'no']\n",
      "['need', 'how'] => ['heed', 'now']\n",
      "['need', 'how'] => ['new', 'hoed']\n",
      "['need', 'dear'] => ['deed', 'near']\n",
      "['need', 'fact'] => ['net', 'faced']\n",
      "['need', 'post'] => ['net', 'posed']\n",
      "['need', 'shows'] => ['news', 'shoed']\n",
      "['to', 'how'] => ['ho', 'tow']\n",
      "['to', 'use'] => ['us', 'toe']\n",
      "['to', 'dear'] => ['do', 'tear']\n",
      "['to', 'not'] => ['no', 'tot']\n",
      "['to', 'copy'] => ['cop', 'toy']\n",
      "['to', 'what'] => ['who', 'tat']\n",
      "['to', 'song'] => ['son', 'tog']\n",
      "['spout', 'trout'] => ['tout', 'sprout']\n",
      "['spout', 'a'] => ['spa', 'out']\n",
      "['spout', 'close'] => ['spouse', 'clot']\n",
      "['spout', 'copy'] => ['copout', 'spy']\n",
      "['exactly', 'just'] => ['exact', 'justly']\n",
      "['exactly', 'secret'] => ['exact', 'secretly']\n",
      "['who', 'and'] => ['wand', 'ho']\n",
      "['who', 'on'] => ['won', 'ho']\n",
      "['who', 'old'] => ['wold', 'ho']\n",
      "['who', 'spam'] => ['spa', 'whom']\n",
      "['ask', 'bus'] => ['busk', 'as']\n",
      "['ask', 'bus'] => ['us', 'bask']\n",
      "['ask', 'packed'] => ['asked', 'pack']\n",
      "['ask', 'but'] => ['busk', 'at']\n",
      "['ask', 'this'] => ['his', 'task']\n",
      "['and', 'use'] => ['used', 'an']\n",
      "['and', 'bus'] => ['us', 'band']\n",
      "['and', 'but'] => ['ant', 'bud']\n",
      "['and', 'not'] => ['ant', 'nod']\n",
      "['and', 'no'] => ['nod', 'an']\n",
      "['and', 'what'] => ['hat', 'wand']\n",
      "['how', 'vid'] => ['vow', 'hid']\n",
      "['how', 'dear'] => ['hoar', 'dew']\n",
      "['how', 'dear'] => ['ear', 'dhow']\n",
      "['how', 'but'] => ['bow', 'hut']\n",
      "['how', 'not'] => ['now', 'hot']\n",
      "['how', 'crazy'] => ['crow', 'hazy']\n",
      "['how', 'no'] => ['now', 'ho']\n",
      "['how', 'silly'] => ['sow', 'hilly']\n",
      "['just', 'but'] => ['bust', 'jut']\n",
      "['use', 'find'] => ['fin', 'used']\n",
      "['use', 'claim'] => ['im', 'clause']\n",
      "['use', 'on'] => ['one', 'us']\n",
      "['use', 'or'] => ['ore', 'us']\n",
      "['use', 'not'] => ['note', 'us']\n",
      "['use', 'fact'] => ['act', 'fuse']\n",
      "['my', 'bus'] => ['ms', 'buy']\n",
      "['my', 'crazy'] => ['cry', 'mazy']\n",
      "['my', 'guess'] => ['guy', 'mess']\n",
      "['my', 'what'] => ['why', 'mat']\n",
      "['my', 'shows'] => ['ms', 'showy']\n",
      "['my', 'shows'] => ['shy', 'mows']\n",
      "['vid', 'close'] => ['vise', 'clod']\n",
      "['vid', 'voice'] => ['void', 'vice']\n",
      "['find', 'bus'] => ['fins', 'bud']\n",
      "['find', 'is'] => ['fins', 'id']\n",
      "['find', 'post'] => ['pond', 'fist']\n",
      "['find', 'no'] => ['nod', 'fin']\n",
      "['precious', 'spam'] => ['specious', 'pram']\n",
      "['trout', 'packed'] => ['pout', 'tracked']\n",
      "['trout', 'spam'] => ['spout', 'tram']\n",
      "['trout', 'copy'] => ['copout', 'try']\n",
      "['on', 'dear'] => ['or', 'dean']\n",
      "['on', 'dear'] => ['den', 'oar']\n",
      "['on', 'dear'] => ['ear', 'don']\n",
      "['on', 'world'] => ['old', 'worn']\n",
      "['on', 'dance'] => ['dan', 'once']\n",
      "['on', 'what'] => ['hat', 'won']\n",
      "['on', 'this'] => ['his', 'ton']\n",
      "['bus', 'old'] => ['bold', 'us']\n",
      "['bus', 'with'] => ['wit', 'bush']\n",
      "['bus', 'packed'] => ['pus', 'backed']\n",
      "['bus', 'not'] => ['no', 'bust']\n",
      "['bus', 'squeaky'] => ['buy', 'squeaks']\n",
      "['bus', 'spam'] => ['bum', 'spas']\n",
      "['bus', 'things'] => ['bugs', 'thins']\n",
      "['bus', 'copy'] => ['buy', 'cops']\n",
      "['bus', 'copy'] => ['cop', 'busy']\n",
      "['bus', 'silly'] => ['bully', 'sis']\n",
      "['bus', 'song'] => ['bug', 'sons']\n",
      "['bus', 'song'] => ['bung', 'sos']\n",
      "['or', 'dear'] => ['ear', 'dor']\n",
      "['or', 'queen'] => ['on', 'queer']\n",
      "['or', 'fact'] => ['act', 'for']\n",
      "['or', 'this'] => ['is', 'thor']\n",
      "['a', 'with'] => ['wit', 'ah']\n",
      "['a', 'not'] => ['no', 'at']\n",
      "['a', 'dance'] => ['dan', 'ace']\n",
      "['a', 'spam'] => ['am', 'spa']\n",
      "['dear', 'queen'] => ['dean', 'queer']\n",
      "['dear', 'packed'] => ['dead', 'packer']\n",
      "['dear', 'not'] => ['near', 'dot']\n",
      "['dear', 'close'] => ['clear', 'dose']\n",
      "['dear', 'no'] => ['near', 'do']\n",
      "['dear', 'spam'] => ['spear', 'dam']\n",
      "['dear', 'silly'] => ['sear', 'dilly']\n",
      "['dear', 'song'] => ['sear', 'dong']\n",
      "['old', 'fact'] => ['act', 'fold']\n",
      "['old', 'what'] => ['hat', 'wold']\n",
      "['old', 'this'] => ['his', 'told']\n",
      "['with', 'world'] => ['wild', 'worth']\n",
      "['with', 'packed'] => ['path', 'wicked']\n",
      "['with', 'keeper'] => ['kith', 'weeper']\n",
      "['with', 'close'] => ['wise', 'cloth']\n",
      "['is', 'but'] => ['it', 'bus']\n",
      "['is', 'spam'] => ['im', 'spas']\n",
      "['packed', 'but'] => ['backed', 'put']\n",
      "['packed', 'but'] => ['packet', 'bud']\n",
      "['packed', 'but'] => ['bucked', 'pat']\n",
      "['packed', 'not'] => ['packet', 'nod']\n",
      "['packed', 'post'] => ['pocked', 'past']\n",
      "['packed', 'videos'] => ['packs', 'videoed']\n",
      "['packed', 'what'] => ['whacked', 'pat']\n",
      "['packed', 'song'] => ['socked', 'pang']\n",
      "['packed', 'shows'] => ['packs', 'showed']\n",
      "['packed', 'shows'] => ['shocked', 'paws']\n",
      "['but', 'not'] => ['no', 'butt']\n",
      "['but', 'post'] => ['bust', 'pot']\n",
      "['but', 'spam'] => ['bum', 'spat']\n",
      "['but', 'guess'] => ['bus', 'guest']\n",
      "['but', 'silly'] => ['bully', 'sit']\n",
      "['but', 'song'] => ['bung', 'sot']\n",
      "['but', 'shows'] => ['shut', 'bows']\n",
      "['keeper', 'shows'] => ['keeps', 'shower']\n",
      "['not', 'close'] => ['clot', 'nose']\n",
      "['close', 'post'] => ['clot', 'posse']\n",
      "['close', 'things'] => ['those', 'clings']\n",
      "['dance', 'silly'] => ['since', 'dally']\n",
      "['squeaky', 'shows'] => ['squeaks', 'showy']\n",
      "['spam', 'what'] => ['spat', 'wham']\n",
      "['things', 'song'] => ['sings', 'thong']\n",
      "['things', 'song'] => ['thing', 'songs']\n",
      "['copy', 'shows'] => ['cops', 'showy']\n",
      "['this', 'song'] => ['thing', 'sos']\n",
      "['this', 'song'] => ['sis', 'thong']\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    for other in words:\n",
    "        other = other.lower()\n",
    "        if word == other: continue\n",
    "        for i in range(1,4):\n",
    "            for j in range(1,4):\n",
    "                affw = word[:i]\n",
    "                affo = other[:j]\n",
    "                suffw = word[-i:]\n",
    "                suffo = other[-j:]\n",
    "\n",
    "                spnw = affo + word[i:]\n",
    "                spno = affw + other[j:]\n",
    "                if spnw in dict and spno in dict:\n",
    "                    skip = (spnw == word or spno == other or spnw == spno or spnw == other or spno == word)\n",
    "                    skip = skip or (f\"{[word, other]} => {[spnw, spno]}\" in res or f\"{[other, word]} => {[spno, spnw]}\" in res)\n",
    "                    skip = skip or (f\"{[word, other]} => {[spno, spnw]}\" in res or f\"{[other, word]} => {[spnw, spno]}\" in res)\n",
    "                    if not skip:\n",
    "                        res.append(f\"{[word, other]} => {[spnw, spno]}\")\n",
    "\n",
    "                spnw = word[:-i] + suffo\n",
    "                spno = other[:-j] + suffw\n",
    "                if spnw in dict and spno in dict:\n",
    "                    skip = (spnw == word or spno == other or spnw == spno or spnw == other or spno == word)\n",
    "                    skip = skip or (f\"{[word, other]} => {[spnw, spno]}\" in res or f\"{[other, word]} => {[spno, spnw]}\" in res)\n",
    "                    skip = skip or (f\"{[word, other]} => {[spno, spnw]}\" in res or f\"{[other, word]} => {[spnw, spno]}\" in res)\n",
    "                    if not skip:\n",
    "                        res.append(f\"{[word, other]} => {[spnw, spno]}\")\n",
    "\n",
    "for i, el in enumerate(res):\n",
    "    print(el)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential improvement\n",
    "- Phonetic matching\n",
    "- Synonyms search\n",
    "- Some refactoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
